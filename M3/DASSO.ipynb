{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryan.liu/.local/share/virtualenvs/M3-9QGq1PG6/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dasso():\n",
    "    def __init__(self, eps=1e-09, verbose=False):\n",
    "        self.eps = eps\n",
    "        self.verbose = verbose\n",
    "        self.betas = []\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        def c(X, y, beta):\n",
    "            return np.matmul(X.T, (y - np.matmul(X, beta)))\n",
    "\n",
    "        def max_covariate_indices(c):\n",
    "            max_covariate = np.max(np.abs(c))\n",
    "            return list(np.argwhere(np.abs(c) > (max_covariate - self.eps)).flatten())\n",
    "\n",
    "        # Also see http://statweb.stanford.edu/~tibs/ftp/lars.pdf, page 7\n",
    "        # Step 2: Let mathcal A be the active set indexing the covariances in c that are \n",
    "        # maximal in absolute value (within numerical error)\n",
    "        def update_mathcal_A(mathcal_A_curr, c):\n",
    "            mci = max_covariate_indices(c)\n",
    "            for idx in mathcal_A_curr:\n",
    "                if idx not in mci:\n",
    "                    mathcal_A_curr.remove(idx)\n",
    "            for idx in mci:\n",
    "                if idx not in mathcal_A_curr:\n",
    "                    mathcal_A_curr.append(idx)\n",
    "\n",
    "        def non_zero_coefficients(beta):\n",
    "            return list(np.argwhere(np.abs(beta) > self.eps).flatten())\n",
    "\n",
    "        # Step 2: Let mathcal_B be the set indexing the non-zero coefficients of beta\n",
    "        def update_mathcal_B(mathcal_B_curr, beta):\n",
    "            nzc = non_zero_coefficients(beta)\n",
    "            for idx in mathcal_B_curr:\n",
    "                if idx not in nzc:\n",
    "                    mathcal_B_curr.remove(idx)\n",
    "            for idx in nzc:\n",
    "                if idx not in mathcal_B_curr:\n",
    "                    mathcal_B_curr.append(idx)\n",
    "            # No op at the end as Python lists are mutable\n",
    "\n",
    "\n",
    "        # Step 3.1\n",
    "        # Let sA be the vector containing the signs of those covariances\n",
    "        def s_mathcal_A(c, mathcal_A):\n",
    "            return np.sign(c[mathcal_A])\n",
    "\n",
    "        # write SA for the diagonal matrix whose diagonal is given by sA\n",
    "        def S_mathcal_A(c, mathcal_A):\n",
    "            return np.diag(s_mathcal_A(c, mathcal_A))\n",
    "\n",
    "        # X with the columns which indices given by mathcal\n",
    "        def X_mathcal(X, mathcal):\n",
    "            return X[:, mathcal]\n",
    "\n",
    "        # S_mathcal_A * (X_mathcal_A)^T * X \n",
    "        def SAXATX(X, c, mathcal_A):\n",
    "            SA = S_mathcal_A(c, mathcal_A)\n",
    "            XAT = X_mathcal(X, mathcal_A).T\n",
    "\n",
    "            return np.matmul(np.matmul(SA, XAT), X)\n",
    "\n",
    "        # Step 3.2\n",
    "        # Write β+ for the positive part of β\n",
    "        def beta_plus(beta):\n",
    "            return np.maximum(beta, 0)\n",
    "\n",
    "        # Write β− for the negative part of β\n",
    "        def beta_minus(beta):\n",
    "            return np.minimum(beta, 0)\n",
    "\n",
    "        # compute the |mathcal_A| × 2p+|mathcal_A| matrix A=(-SAXTAX SAXTAX I), \n",
    "        # where I is the identity matrix\n",
    "        def A(X, c, mathcal_A):\n",
    "            A = -1 * SAXATX(X, c, mathcal_A)\n",
    "            A = np.append(A, SAXATX(X, c, mathcal_A), axis=1)\n",
    "            A = np.append(A, np.identity(len(mathcal_A)), axis=1)\n",
    "\n",
    "            return A\n",
    "\n",
    "        def q(A, B_1, B_2):\n",
    "            # The row dimension of A is |mathcal_A|\n",
    "            dim_mathcal_A = A.shape[0]\n",
    "\n",
    "            return [A[(dim_mathcal_A - 1), i] -\n",
    "                    np.matmul(np.matmul(B_2, np.linalg.inv(B_1)), \n",
    "                              A[0:(dim_mathcal_A - 1), i])\n",
    "                    for i in range(0, A.shape[1])]\n",
    "\n",
    "        def alpha(B_1, B_2):\n",
    "            # The row dimension of B_1 is |mathcal_A| - 1\n",
    "            dim_mathcal_A = B_1.shape[0] + 1\n",
    "\n",
    "            return np.matmul(np.matmul(B_2, np.linalg.inv(B_1)), \n",
    "                             np.ones((dim_mathcal_A - 1, 1))) - 1\n",
    "\n",
    "        def i_star(A, B_tilde):\n",
    "            dim_mathcal_A = A.shape[0]\n",
    "            dim_p = (A.shape[1] - dim_mathcal_A) / 2\n",
    "            assert (dim_p.is_integer())\n",
    "            assert (B_tilde.shape[1] == (dim_mathcal_A - 1))\n",
    "\n",
    "            B_1 = B_tilde[0:(dim_mathcal_A - 1), :]\n",
    "            B_2 = B_tilde[dim_mathcal_A - 1, :]\n",
    "\n",
    "            _q = q(A, B_1, B_2)\n",
    "            _alpha = alpha(B_1, B_2)\n",
    "\n",
    "            vals = [\n",
    "                (np.matmul(np.matmul(np.ones(dim_mathcal_A - 1), np.linalg.inv(B_1)),\n",
    "                           A[0:(dim_mathcal_A - 1), i]) - \n",
    "                 (1 if i < (2 * dim_p) else 0)\n",
    "                ) / np.abs(_q[i])\n",
    "                if ((np.abs(_q[i]) > self.eps) and ((_alpha / _q[i]) > self.eps)) else -np.inf\n",
    "                for i in range(0, A.shape[1])\n",
    "            ]\n",
    "\n",
    "            max_val = np.max(vals)\n",
    "            return(np.argwhere(vals >= (max_val - self.eps)).flatten()[0])\n",
    "\n",
    "        # Use the new mathcal_A and mathcal_B to calculate the |mathcal_B|-dimensional\n",
    "        # direction vector h_mathcal_B =((X_mathcal_A)^T * X_mathcal_B)^(−1) * s_mathcal_A. \n",
    "        def h_mathcal_B(X, c, mathcal_A, mathcal_B):\n",
    "            return np.matmul(\n",
    "                np.linalg.inv(np.matmul(X_mathcal(X, mathcal_A).T, \n",
    "                                        X_mathcal(X, mathcal_B))),\n",
    "                s_mathcal_A(c, mathcal_A))\n",
    "\n",
    "        # Let h be the p-dimensional vector with the components corresponding to \n",
    "        # mathcal_B given by h_mathcal_B and the remainder set to 0.\n",
    "        def h(X, c, mathcal_A, mathcal_B):\n",
    "            dim_p = X.shape[1]\n",
    "            _h_mathcal_B = h_mathcal_B(X, c, mathcal_A, mathcal_B)\n",
    "\n",
    "            _h = np.zeros(dim_p)\n",
    "            for mathcal_B_idx, h_idx in enumerate(mathcal_B, start=0):\n",
    "                _h[h_idx] = _h_mathcal_B[mathcal_B_idx]\n",
    "\n",
    "            return _h\n",
    "\n",
    "        # The first occurs at the point where a new variable enters the active set mathcal_A.\n",
    "        def gamma_1(X, c, h, mathcal_A):\n",
    "            dim_p = X.shape[1]\n",
    "            mathcal_A_comp = np.setdiff1d(range(0, X.shape[1]), mathcal_A)\n",
    "            \n",
    "            # LARS paper P.416, lines 6-8: The exception is at the last stage: since Am contains all covariates, \n",
    "            # (2.13) is not defined.\n",
    "            if len(mathcal_A_comp) == 0:\n",
    "                return(np.max(np.abs(c)))\n",
    "            # TODO: A_m is missing here\n",
    "            \n",
    "            else:\n",
    "                vals = np.array([\n",
    "                    (c[k] - c[j]) /\n",
    "                    np.matmul(np.matmul((X[:, k] - X[:, j]).T, X), h)\n",
    "                    if np.abs(np.matmul(np.matmul((X[:, k] - X[:, j]).T, X), h)) > self.eps else 0\n",
    "                    for k in mathcal_A for j in mathcal_A_comp\n",
    "                ])\n",
    "\n",
    "                vals = np.append(\n",
    "                    vals, \n",
    "                    np.array([\n",
    "                        (c[k] + c[j]) /\n",
    "                        np.matmul(np.matmul((X[:, k] + X[:, j]).T, X), h)\n",
    "                        if np.abs(np.matmul(np.matmul((X[:, k] + X[:, j]).T, X), h)) > self.eps else 0\n",
    "                        for k in mathcal_A for j in mathcal_A_comp])\n",
    "                )\n",
    "\n",
    "                # min+ is the minimum taken over the positive components only\n",
    "                return (np.min([val if val > self.eps else np.inf for val in vals]) \n",
    "                        if len(vals) > 0 else np.inf)\n",
    "\n",
    "        # The second possible break in the path occurs if a coefficient path crosses zero, \n",
    "        # i.e. β_j + γ*h_j =0. It is easily verified that the corresponding distance is \n",
    "        # given by γ_2 = min+_j {−β_j/h_j}. \n",
    "        def gamma_2(beta, h):\n",
    "            # Assuming they mean all j, not j in mathcal_(A^comp)\n",
    "            vals = np.array([\n",
    "                (-beta[j] / h[j]) if (np.abs(h[j]) > self.eps) else 0\n",
    "                for j in range(0, h.shape[0])\n",
    "            ])\n",
    "\n",
    "            # min+ is the minimum taken over the positive components only\n",
    "            return np.min([val if val > self.eps else np.inf for val in vals])\n",
    "\n",
    "        def gamma(X, beta, c, h, mathcal_A):\n",
    "            return min(gamma_1(X, c, h, mathcal_A),\n",
    "                       gamma_2(beta, h))\n",
    "\n",
    "        self.betas = []\n",
    "        dim_n = X.shape[0]\n",
    "        dim_p = X.shape[1]\n",
    "\n",
    "        # Step 1\n",
    "        beta = np.zeros(dim_p)\n",
    "        l = 1\n",
    "        mathcal_A = []\n",
    "        mathcal_B = []\n",
    "        \n",
    "        while True:\n",
    "            # Step 2\n",
    "            update_mathcal_B(mathcal_B, beta)\n",
    "\n",
    "            _c = c(X, y, beta)\n",
    "            update_mathcal_A(mathcal_A, _c)\n",
    "\n",
    "            sA = s_mathcal_A(_c, mathcal_A)\n",
    "            \n",
    "            assert len(mathcal_A) == (len(mathcal_B) + 1)\n",
    "\n",
    "            # Step 3\n",
    "            if (len(mathcal_B) == 0):\n",
    "                mathcal_B.append(max_covariate_indices(_c)[0])\n",
    "            else:\n",
    "                # Appendix 1, step 1\n",
    "                _A = A(X, _c, mathcal_A)\n",
    "\n",
    "                # Appendix 1, step 2\n",
    "                B_tilde = _A[:, np.concatenate(\n",
    "                    (np.argwhere(np.abs(beta_plus(beta)) > self.eps).flatten(),\n",
    "                     dim_p + np.argwhere(np.abs(beta_minus(beta)) > self.eps).flatten()))]\n",
    "                _i_star = i_star(_A, B_tilde)\n",
    "\n",
    "                # Appendix 1, step 3\n",
    "                if _i_star < (2 * dim_p):\n",
    "                    if (_i_star % dim_p) not in mathcal_B:\n",
    "                        mathcal_B.append(_i_star % dim_p)\n",
    "                else:\n",
    "                    del mathcal_A[(_i_star - 2 * dim_p)]\n",
    "\n",
    "            assert len(mathcal_A) == len(mathcal_B)\n",
    "\n",
    "            _h = h(X, _c, mathcal_A, mathcal_B)\n",
    "\n",
    "            # Step 4\n",
    "            _gamma = gamma(X, beta, _c, _h, mathcal_A)\n",
    "            \n",
    "            self.betas.append(beta)\n",
    "            beta = beta + _gamma * _h\n",
    "\n",
    "            # Step 5\n",
    "            max_covar = np.abs(np.max(c(X, y, beta)))\n",
    "            if max_covar < self.eps:\n",
    "                break\n",
    "\n",
    "            if (l % 10 == 0) and self.verbose:\n",
    "                print(\"Iteration {}: ||c||_inf = {}\".format(l, max_covar),\n",
    "                      end=\"\\r\")\n",
    "            l += 1\n",
    "\n",
    "        print(\"Iteration {}: ||c||_inf = {}\".format(l, max_covar), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_n = 64\n",
    "dim_p = 128\n",
    "dim_s = 10\n",
    "\n",
    "X = np.random.normal(0, 1, (dim_n, dim_p))\n",
    "\n",
    "beta_true = np.zeros(dim_p)\n",
    "for i in np.random.choice(range(0, dim_p), dim_s, replace=False):\n",
    "    beta_true[i] = np.random.normal(0, 1)\n",
    "\n",
    "Y = np.matmul(X, beta_true) + np.random.normal(0, 0.5, dim_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 489: ||c||_inf = 2.5702596539452954e-10\r"
     ]
    }
   ],
   "source": [
    "# DASSO algorithm\n",
    "dasso_random = Dasso(verbose=True)\n",
    "dasso_random.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diabetes, y_diabetes = ds.load_diabetes(return_X_y=True)\n",
    "y_diabetes = y_diabetes - y_diabetes.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] []\n",
      "[2, 8] [2]\n",
      "[2, 8, 3] [2, 8]\n",
      "[2, 8, 3, 6] [2, 8, 3]\n",
      "[2, 8, 3, 6, 1] [2, 8, 3, 6]\n",
      "[2, 8, 3, 6, 1, 9] [2, 8, 3, 6, 1]\n",
      "[2, 8, 3, 6, 1, 9, 4] [2, 8, 3, 6, 1, 9]\n",
      "[2, 8, 3, 6, 1, 9, 4, 7] [2, 8, 3, 6, 1, 9, 5]\n",
      "[2, 8, 3, 1, 9, 4, 7, 6] [2, 8, 3, 6, 1, 9, 5]\n",
      "[2, 8, 3, 1, 9, 4, 7, 6, 5] [2, 8, 3, 6, 1, 9, 5, 7]\n",
      "Iteration 10: ||c||_inf = 4.372057271205559\r",
      "[2, 8, 3, 1, 9, 4, 7, 6, 5, 0] [2, 8, 3, 6, 1, 9, 5, 7, 4]\n",
      "[2, 8, 3, 1, 9, 4, 7, 6, 5, 0] [2, 8, 3, 6, 1, 9, 7, 4, 0]\n",
      "[8, 3, 1, 9, 4, 7, 6, 5, 0, 2] [2, 8, 3, 6, 1, 9, 7, 4, 0]\n",
      "[8, 3, 1, 9, 4, 7, 6, 5, 0, 2] [2, 8, 3, 1, 9, 7, 4, 0, 5]\n",
      "Iteration 14: ||c||_inf = 1.6868728636154628e-12\r"
     ]
    }
   ],
   "source": [
    "# DASSO algorithm\n",
    "dasso = Dasso(eps=1e-11, verbose=True)\n",
    "dasso.fit(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston, y_boston = ds.load_boston(return_X_y=True)\n",
    "y_boston = y_boston - y_boston.mean()\n",
    "X_boston = X_boston - np.mean(X_boston, axis=0)\n",
    "X_boston = X_boston / np.sqrt(np.sum(X_boston**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] []\n",
      "[12, 5] [12]\n",
      "[12, 5, 10] [12, 5]\n",
      "[12, 5, 10, 11] [12, 5, 10]\n",
      "[12, 5, 10, 11, 3] [12, 5, 10, 11]\n",
      "[12, 5, 10, 11, 3, 0] [12, 5, 10, 11, 3]\n",
      "[5, 10, 11, 3, 0, 7] [12, 5, 10, 11, 3]\n",
      "[5, 10, 11, 3, 0, 7, 12] [12, 5, 10, 11, 3, 0]\n",
      "[5, 10, 11, 3, 0, 7, 12, 4] [12, 5, 10, 11, 3, 0, 7]\n",
      "[5, 10, 11, 3, 0, 7, 12, 4] [12, 5, 10, 11, 3, 7, 9]\n",
      "Iteration 10: ||c||_inf = 8.516250354335263\r",
      "[5, 10, 11, 3, 7, 12, 4, 1] [12, 5, 10, 11, 3, 7, 9]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0] [12, 5, 10, 11, 3, 7, 9]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5] [12, 5, 10, 11, 3, 7, 9, 8]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8] [12, 5, 10, 11, 3, 7, 9, 8, 4]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8] [12, 5, 10, 11, 3, 7, 8, 4, 0]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8] [12, 5, 10, 11, 3, 7, 4, 0, 1]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8, 9] [12, 5, 10, 11, 3, 7, 4, 0, 1, 8]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8, 9, 2] [12, 5, 10, 11, 3, 7, 4, 0, 1, 8, 2]\n",
      "[10, 11, 3, 7, 12, 4, 1, 0, 5, 8, 9, 2] [12, 5, 10, 11, 3, 7, 4, 0, 1, 8, 9]\n",
      "[10, 11, 7, 12, 4, 1, 0, 5, 8, 9, 2, 3] [12, 5, 10, 11, 3, 7, 4, 0, 1, 8, 9]\n",
      "Iteration 20: ||c||_inf = 0.07829945149555073\r",
      "[10, 11, 7, 12, 4, 1, 0, 5, 8, 9, 2, 3, 6] [12, 5, 10, 11, 3, 7, 4, 0, 1, 8, 9, 2]\n",
      "Iteration 21: ||c||_inf = 1.452449271965861e-13\r"
     ]
    }
   ],
   "source": [
    "dasso_boston = Dasso(eps=5e-13, verbose=True)\n",
    "dasso_boston.fit(X_boston, y_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
